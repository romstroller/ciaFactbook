{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from FileTools import FileTools\n",
    "# from pprint import pprint\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "import pickle\n",
    "#import random\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "#import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# authenticate with API\n",
    "\n",
    "currWorkDir = os.getcwd()\n",
    "userDir = Path.home()\n",
    "keyPath = f\"{userDir}\\\\PYC\\\\ADMIN\\\\kaggle.json\"\n",
    "\n",
    "with open( keyPath, 'r' ) as f: keyDict = json.load( f )\n",
    "userTitle, keyTitle = keyDict.keys()\n",
    "kaggleUsername, kaggleKey = keyDict[ userTitle ], keyDict[ keyTitle ]\n",
    "\n",
    "os.environ[ 'KAGGLE_USERNAME' ] = kaggleUsername\n",
    "os.environ[ 'KAGGLE_KEY' ] = kaggleKey\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# retrieve dataset\n",
    "datasetOwner = 'lucafrance'\n",
    "datasetName = 'the-world-factbook-by-cia'\n",
    "api.dataset_download_files( f'{datasetOwner}/{datasetName}', path=\".\" )\n",
    "\n",
    "# await download\n",
    "fTools = FileTools()\n",
    "datasetFName = None\n",
    "print( \"Waiting for dataset download\" )\n",
    "while True:\n",
    "    time.sleep( 1 )\n",
    "    sortedFs = fTools.datesortFiles( currWorkDir, datasetName )\n",
    "    if len( sortedFs ) == 0: continue\n",
    "    datasetFName = list( sortedFs )[ 0 ]\n",
    "    print( f\"Latest: {datasetFName}\" )\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# extract and identify datafiles\n",
    "\n",
    "origDataDir = f\"{currWorkDir}\\\\data_or\"\n",
    "if not os.path.exists( origDataDir ): os.makedirs( origDataDir )\n",
    "\n",
    "if datasetFName and Path( datasetFName ).suffix == \".zip\":\n",
    "    with ZipFile( datasetFName, 'r' ) as zipF: zipF.extractall( origDataDir )\n",
    "\n",
    "dataPaths = [ f\"{origDataDir}\\\\{pth}\" for pth in os.listdir( origDataDir )\n",
    "    if Path( pth ).suffix == \".csv\" ]\n",
    "\n",
    "if len( dataPaths ) > 0:\n",
    "    dffBook = pd.read_csv( [ pth for pth in dataPaths ][ 0 ] )\n",
    "    print( \"Got dffBook DF from extracted dataset at:\\n\", dataPaths[ 0 ] )\n",
    "else: print( \"Failed get CSV\" ); sys.exit()\n",
    "\n",
    "dffBook\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def excludeParenth( _mtchLi, _val ):\n",
    "    mtchLi = [ ]\n",
    "    # # Drop value if between parentheses (pre-match open count > close count)\n",
    "    for match in _mtchLi:\n",
    "        matchDex = _val.index( match )\n",
    "        openCount = _val[ :matchDex ].count( '(' )\n",
    "        closCount = _val[ :matchDex ].count( ')' )\n",
    "        parenthesised = openCount > closCount\n",
    "        if not parenthesised: mtchLi.append( match )\n",
    "    \n",
    "    return mtchLi\n",
    "\n",
    "\n",
    "def getMatchRemain( df_in, coIdex, patrn ):\n",
    "    \n",
    "    # get any number-pattern match from each row in a list\n",
    "    mtches = df_in.iloc[ :, coIdex ].str.findall( patrn )\n",
    "    # store non-number remainder of string (potential unit etc)\n",
    "    rmnder = [ ]\n",
    "    mtches_ret = []\n",
    "    pos = 0\n",
    "    for roVal in df_in.iloc[ :, coIdex ]:\n",
    "        \n",
    "        matchLi = mtches[ pos ]\n",
    "        if type( matchLi ) != list: rmnt = None\n",
    "        elif len( matchLi ) == 1: rmnt = roVal\n",
    "        elif len( matchLi ) > 1: rmnt = roVal[ :roVal.index( matchLi[ 1 ] ) ]\n",
    "        else: rmnt = None\n",
    "        \n",
    "        if rmnt:\n",
    "            # is non-float and is list, exclude any parenthesised matches \n",
    "            matchLi = excludeParenth( mtches[ pos ], roVal )\n",
    "            mtches_ret.append(matchLi)\n",
    "            if len(matchLi)>0: \n",
    "                # exclude main value candidate  \n",
    "                rmnder.append( rmnt.replace( matchLi[ 0 ], '' ) )\n",
    "                \n",
    "        else:\n",
    "            # NEED APPEND FLOAT_ONLY MATCH; THIS FL+EMPLIST\n",
    "            if type(matchLi)==float: mtches_ret.append(matchLi)  \n",
    "            else: matchLi.append(np.nan)   \n",
    "            rmnder.append( \"\" )\n",
    "            \n",
    "        pos += 1\n",
    "    \n",
    "    return mtches_ret, rmnder\n",
    "\n",
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "serbDex = dffBook[dffBook['Country'] == 'Serbia'].index[0]# LIMITED\n",
    "serbDex"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# MATCHING NUMBERS\n",
    "# REGEX:\n",
    "#   capture group             (                 \n",
    "#   zero/one                  [+-]?             possible number sign\n",
    "#   1-3 nums                  \\d{1,3}           up to three straight nums\n",
    "#   non-capture subgroup      (?:               possible thousand-groups\n",
    "#     comma and 3 nums          ,\\d{3}          (sep. comma)\n",
    "#     zero or more times        )*              \n",
    "#   non-capture subgroup      (?:               then possible decimal part\n",
    "#     decimal and 1+nums        \\.\\d+           \n",
    "#     zero/one time             )?            \n",
    "#   OR (alt. to last seq)     |                 or no groups, just              \n",
    "#     0+ nums, dec, 1+nums      \\d*\\.\\d+        more nums and poss decimal\n",
    "#   OR (alt. to last seq)     |             \n",
    "#     1+ nums                   \\d+             or just more numbers.\n",
    "#   Close capture group       )\n",
    "#   ( match basic number last to capture greatest valid str segment )\n",
    "\n",
    "patt = re.compile( r'([+-]?\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?|\\d*\\.\\d+|\\d+)' )\n",
    "\n",
    "dfFbDict = { }  # to collect column data during cleaning\n",
    "checkTypes = { }\n",
    "\n",
    "# colDex = 1                                        # TESTING\n",
    "colDex = list(dffBook.columns).index(\"Environment: Total water withdrawal - agricultural\")\n",
    "                                                    # TESTING\n",
    "for colName in dffBook.columns[ colDex: colDex+1 ]: # TESTING [ colDex: ]:\n",
    "    origCol = dffBook.iloc[ :, colDex ]\n",
    "    colType = dffBook[ colName ].dtype\n",
    "    \n",
    "    print(origCol[serbDex])                         # TESTING\n",
    "    \n",
    "    # get match if string, store if already float, catch unexpected\n",
    "    if colType == float:\n",
    "        colDict = { 'matchedNums': origCol, 'remainder': [ ] }\n",
    "    elif colType == np.float64:\n",
    "        colDict = { 'matchedNums': origCol.astype( float ), 'remainder': [ ] }\n",
    "    else:\n",
    "        matches, remainder = getMatchRemain( dffBook, colDex, patt )\n",
    "        colDict = { 'matchedNums': matches, 'remainder': remainder }\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(matches[serbDex])                     # TESTING\n",
    "        print(remainder[serbDex])                   # TESTING\n",
    "        \n",
    "    \n",
    "    colDict[ 'origCol' ] = origCol\n",
    "    dfFbDict[ colName ] = colDict\n",
    "    colDex += 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# RESTRICT TO & DISPLAY VALUES FOR SERB - AGRIWATER THROUGH PROCESS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print( \"This should be 660.8 million: \", \n",
    "    dffBook.loc[ dffBook[ 'Country' ] == \"Serbia\", \n",
    "    \"Environment: Total water withdrawal - agricultural\" ].iloc[ 0 ] )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raise Exception(\"stop here\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# split first match item from list as float to \"clean\", store else to \"split\"\n",
    "def splitFirstOther( matchList ):\n",
    "    firstVals, splitVals, checkVals = [ ], [ ], [ ]\n",
    "    for mNum in range( len( matchList ) ):\n",
    "        el = matchList[ mNum ]\n",
    "        isFilldList = (type( el ) == list) and (len( el ) > 0)\n",
    "        if isFilldList:  # remove any thousandcomma to support convert\n",
    "            firstVals.append( float( ''.join( el[ 0 ].split( ',' ) ) ) )\n",
    "            splitVals.append( [ v for v in el[ 1: ] ] )\n",
    "        else:  # check all else are either nan or empty matchlist\n",
    "            if ((type( el ) == list and len( el ) > 0) or\n",
    "                (type( el ) != list and math.isnan( el ) == False)):\n",
    "                checkVals.append( el )\n",
    "            firstVals.append( np.nan )\n",
    "            splitVals.append( np.nan )\n",
    "    return firstVals, splitVals, checkVals\n",
    "\n",
    "\n",
    "for colName in dfFbDict:\n",
    "    colDict = dfFbDict[ colName ]\n",
    "    colDict[ 'clean' ], colDict[ 'splitVals' ], colDict[ 'checkVals' ] = (\n",
    "        splitFirstOther( colDict[ 'matchedNums' ] ))\n",
    "\n",
    "# Raise message if got uncategorized data\n",
    "for colName in dfFbDict:\n",
    "    if len( dfFbDict[ colName ][ 'checkVals' ] ) > 0:\n",
    "        print( f\"Got checkvals for {colName}\" )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# dictionary columns to DF, checking is now float\n",
    "newCols = [ ]\n",
    "dfFloat = dffBook.iloc[ :, 0 ]  # start with countries\n",
    "for colName in dfFbDict:\n",
    "    clean = pd.Series( dfFbDict[ colName ][ 'clean' ] )\n",
    "    lenFloat = len( [ i for i in clean if type( i ) == float ] )\n",
    "    if lenFloat > len( clean ) * 0.90:\n",
    "        newCols.append( colName )\n",
    "        dfFloat = pd.concat( [ dfFloat, clean ], axis=1 )\n",
    "    else: print( \"col is less than 90% float. Dropping...\" )\n",
    "\n",
    "dfFloat.columns = [ 'Country' ] + newCols\n",
    "dfFloat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Enforce non-nan threshold for dimensions\n",
    "\n",
    "def nanThreshold( notNan ):  # average plus .5 standard deviation (rounded)\n",
    "    return int( (sum( notNan ) / len( notNan )) + 0.5 * np.std( notNan ) )\n",
    "\n",
    "\n",
    "def nonNanFromDims( dfr, dim = 1 ):\n",
    "    nonNans = [ ]\n",
    "    for pos in range( 0, dfr.shape[ dim ] ):\n",
    "        if dim == 1: vals = dfr.iloc[ :, pos ].tolist()\n",
    "        else: vals = dfr.loc[ [ pos ] ].values.tolist()[ 0 ]\n",
    "        \n",
    "        nonNans.append( [ vals, len( [ v for v in vals if\n",
    "            type( v ) == float and not math.isnan( v ) ] ) ] )\n",
    "    \n",
    "    _thresh = nanThreshold( [ nval for _, nval in nonNans ] )\n",
    "    keepVals = [ kval for kval, nnul in nonNans if nnul >= _thresh ]\n",
    "    print( f\"non-nan[ {len( keepVals )} ] thr[ {_thresh} ] dim[ {dim} ]\" )\n",
    "    \n",
    "    return keepVals"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# DROP ROWS - disabled to keep all significant countries\n",
    "def cleanRows():\n",
    "    dfClean = pd.DataFrame( nonNanFromDims( dfFloat, dim=0 ) )\n",
    "    # add a columnindex row to track names of kept columns\n",
    "    dfClean.loc[ -1 ] = dfFloat.columns\n",
    "    dfClean.index = dfClean.index + 1\n",
    "    dfClean.sort_index( inplace=True )\n",
    "    return dfClean\n",
    "\n",
    "# dfRowsClean = cleanRows()\n",
    "# keepCols_RC = nonNanFromDims( dfRowsClean, dim=1 )\n",
    "# # convert to numeric df - row-cleaned\n",
    "# dfRCC = pd.DataFrame( { col[ 0 ]: col[ 1: ] for col in keepCols_RC } )\n",
    "# dfRCC = dfRCC.apply( pd.to_numeric, errors='ignore' )\n",
    "# dfColsClean = dfRCC"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CLEAN COLS to numeric, adding featname row for tracking through clean\n",
    "dfFloat.loc[ -1 ] = dfFloat.columns\n",
    "dfFloat.index = dfFloat.index + 1\n",
    "dfFloat.sort_index( inplace=True )\n",
    "keepCols = nonNanFromDims( dfFloat, dim=1 )\n",
    "dfColsClean = pd.DataFrame( { col[ 0 ]: col[ 1: ] for col in keepCols } )\n",
    "dfColsClean = dfColsClean.apply( pd.to_numeric, errors='ignore' )\n",
    "dfColsClean.insert( 0, 'Country', dfFloat.iloc[ :, 0 ].tolist()[ 1: ] )\n",
    "dfColsClean\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Review clean DF\n",
    "fbIsNa = dffBook.isna().sum().sum()\n",
    "dfIsNa = dfColsClean.isna().sum().sum()\n",
    "fbDim = dffBook.shape[ 0 ] * dffBook.shape[ 1 ]\n",
    "dfDim = dfColsClean.shape[ 0 ] * dfColsClean.shape[ 1 ]\n",
    "print( f\"factbook originally shape: {dffBook.shape}\" )\n",
    "print( f\"    NAN-density: {(fbIsNa / fbDim):.2f}% \"\n",
    "       f\"({fbIsNa} NaN in {fbDim})\" )\n",
    "print( f\"clean dataframe has shape: {dfColsClean.shape}\" )\n",
    "print( f\"    NAN-density: {(dfIsNa / dfDim):.2f}% \"\n",
    "       f\"({dfIsNa} NaN in {dfDim})\" )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Reporting to identify any differences of unit scale within features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Add some further cleaning to remainder to reduce non-unit variations\n",
    "\n",
    "def cleanRemainder():\n",
    "    cleanPatts = [\n",
    "        r'(\\([^)]*\\))',  # remove all bracketed\n",
    "        r'(.* m)$|(.* m) '  # remove all before \" m[endline/space]\" (mtn names)\n",
    "        ]\n",
    "    \n",
    "    cleanReman = { }\n",
    "    \n",
    "    for col in list( dfFloat.columns )[ 1: ]:\n",
    "        remainder = dfFbDict[ col ][ 'remainder' ]\n",
    "        for pattStr in cleanPatts:\n",
    "            pattrn = re.compile( pattStr )\n",
    "            remainder = remainder.str.replace( pattrn, '' )\n",
    "        cleanReman.update( { colName: remainder } )\n",
    "    \n",
    "    return cleanReman\n",
    "\n",
    "# cleanReman = cleanRemainder()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CHECK FOR SCALE FACTORS /GENERAL FEATURE ANALYSIS/SELECTIOn\n",
    "\n",
    "def runScaleAnalysis( dfr, remDict ):\n",
    "    colList = list( dfr.columns )\n",
    "    dropFeatrs = [ ]\n",
    "    cleanNotes = { }\n",
    "    \n",
    "    for pos in range( 1, len( colList ) ):\n",
    "        colNam = colList[ pos ]\n",
    "        colSeg = dfr.iloc[ :, pos ].tolist()[ :10 ]\n",
    "        remndr = set( remDict[ colNam ] )\n",
    "        rMainPrint = \"\"\n",
    "        for r in list( remndr )[ :25 ]:\n",
    "            if type( r ) == float: rMainPrint = rMainPrint + f\"{r}\\n\"\n",
    "            else: rMainPrint = rMainPrint + f\"{r[ :60 ]}\\n\"\n",
    "        \n",
    "        report = (f\"COL [ {pos} ] {colNam}\\n\\n\"\n",
    "                  f\"CLEANVALS:\\n{colSeg}\\n\\n\"\n",
    "                  f\"REMAINDER (unq in col: {len( remndr )}):\\n{rMainPrint}\\n\")\n",
    "        \n",
    "        report_a = report + \"\\nACCEPT(A), BREAK(B), CLEAN/SCALE NOTE(C), DROP(D)\"\n",
    "        report_b = report_a + \"\\n\\nPLEASE MAKE A SELECTION:\\n\\n\"\n",
    "        usinp = input( report_a )\n",
    "        while usinp not in [ 'a', 'd', 'c', 'b' ]: usinp = input( report_b )\n",
    "        if usinp == 'b': break\n",
    "        elif usinp == 'a': continue\n",
    "        elif usinp == 'd': dropFeatrs.append( colNam )\n",
    "        else: cleanNotes.update( {\n",
    "            colNam: input( f\"{report[ :250 ]}...\\n\\n\\nCLEANING/SCALE NOTE\" ) } )\n",
    "    \n",
    "    return dropFeatrs, cleanNotes\n",
    "\n",
    "# dropFeatrs, cleanNotes = runScaleAnalysis(dfColsClean, cleanReman)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # SAVE SCALE ANALYSIS DATA\n",
    "# stmp = fTools.dtStamp()\n",
    "# fTools.storePKL( dropFeatrs, f'dropFeatrs_{stmp}', currWorkDir, subdir=None )\n",
    "# fTools.storePKL( cleanNotes, f'cleanNotes_{stmp}', currWorkDir, subdir=None )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# LOAD SCALE ANALYSIS DATA\n",
    "pklFiles = [ fi for fi in\n",
    "    [ open( pth, 'rb' ) for pth in\n",
    "        [ list( dKey )[ 0 ] for dKey in\n",
    "            [ fTools.datesortFiles( currWorkDir, fNam ) for fNam in\n",
    "                [ 'dropFeatrs', 'cleanNotes' ] ] ] ] ]\n",
    "\n",
    "dropFeats, scaleNotes = [ pickle.load( fi ) for fi in pklFiles ]\n",
    "for fi in pklFiles: fi.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = dfColsClean.copy()\n",
    "for i in dropFeats:\n",
    "    try: df.drop( [ i ], axis=1, inplace=True )\n",
    "    except KeyError: pass\n",
    "scaleKeys = [ dkey for dkey in scaleNotes if dkey not in dropFeats ]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# update value by matching remainder scale fragment via country reference\n",
    "\n",
    "dct = dfFbDict.copy()\n",
    "\n",
    "scaleDict = {\n",
    "    \"million\": 1000000,\n",
    "    \"billion\": 1000000000,\n",
    "    \"trillion\": 1000000000000 }\n",
    "\n",
    "cleanCountries = list( df[ 'Country' ] )\n",
    "\n",
    "for colName in scaleKeys:\n",
    "    colVals = [ ]\n",
    "    row = 0\n",
    "    \n",
    "    # checking remnantcol (HAS PRE-CLEAN ENTRIES) for match\n",
    "    for remnt in dct[ colName ][ 'remainder' ]:\n",
    "        # print( remnt, \"___\" )\n",
    "        country = dffBook[ 'Country' ][ row ]\n",
    "        if country not in cleanCountries: row += 1; continue\n",
    "        val = df.loc[ df[ 'Country' ] == country ][ colName ].iloc[ 0 ]\n",
    "        if type( remnt ) == float: row += 1; colVals.append( val ); continue\n",
    "        if remnt.startswith( \"-$\" ): val = 0 - val  # fix $ breaking neg float\n",
    "        \n",
    "        matches = [ ]\n",
    "        for scale in scaleDict:  # apply lowest-index matched scale\n",
    "            try: matches.append( [ remnt.index( scale ), scale ] )\n",
    "            except ValueError: continue\n",
    "        if len( matches ) > 0:  # sort by lowest index (first val of match)\n",
    "            matchScale = sorted( matches, key=lambda x: x[ 0 ] )[ 0 ][ 1 ]\n",
    "            val = val * scaleDict[ matchScale ]\n",
    "        \n",
    "        colVals.append( val )\n",
    "        row += 1\n",
    "    \n",
    "    df[ colName ] = colVals\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # for colName in list(dfFbDict.keys())[5:6]:\n",
    "# coldict = dfFbDict['Geography: Area - total']\n",
    "# row = 0\n",
    "# for rmnt in coldict['remainder']:\n",
    "#     print( f\"MATCH [{df['Geography: Area - total'][row]}] \"\n",
    "#         f\"FROM RMNT: {rmnt}\" )\n",
    "#     row +=1\n",
    "\n",
    "# \n",
    "# dfWater = pd.concat( [ df[ 'Country' ],\n",
    "#     pd.Series( df[ 'Geography: Area - water' ] ),\n",
    "#     pd.Series( df[ 'Geography: Area - total' ]) ], \n",
    "#     axis=1 ).sort_values( by=[ 'Geography: Area - water' ],\n",
    "#     ascending=False )\n",
    "# \n",
    "# # remnant logic change has broken scale matching\n",
    "# \n",
    "# print(dfWater[ dfWater.Country == 'Chad' ])\n",
    "# print(dffBook[ dffBook.Country == 'Chad' ]['Geography: Area - water'])\n",
    "# print(dffBook[ dffBook.Country == 'Chad' ]['Geography: Area - total'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# raise ValueError"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# remove \"World\" until needed\n",
    "dfWorld = df[ df.Country == 'World' ].copy()\n",
    "df = df[ df.Country != 'World' ].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# a few top and bottom tens\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# need to go back and get units\n",
    "def showTopTen( featName, _df, asc = False, subtitle = None, unit = None ):\n",
    "    print( featName )\n",
    "    \n",
    "    df10 = pd.concat( [ _df[ 'Country' ],\n",
    "        pd.Series( _df[ featName ] ) ], axis=1 ).sort_values( by=[ featName ],\n",
    "        ascending=asc )[ :10 ]\n",
    "    \n",
    "    fig = plt.figure( facecolor=\"silver\" )\n",
    "    # plt.tight_layout()\n",
    "    \n",
    "    ax = fig.add_axes( [ 0, 0, 1.2, 1.2 ] )\n",
    "    ax.bar( df10.iloc[ :, 0 ], df10.iloc[ :, 1 ] )\n",
    "    \n",
    "    title = f\"{'BOTTOM' if asc else 'TOP'} TEN\\n{featName}\"\n",
    "    if subtitle: title = f\"{title}\\n({subtitle})\"\n",
    "    if unit: title = f\"{title}\\n[{unit}]\"\n",
    "    \n",
    "    ax.set_title( title, fontsize=16, ha=\"right\", weight=\"demi\", x=0.98,\n",
    "        color=\"black\" )\n",
    "    \n",
    "    ax.ticklabel_format( axis='y', useOffset=False, style='plain' )\n",
    "    for tick in ax.yaxis.get_major_ticks():\n",
    "        tick.label.set_fontsize( 14 )\n",
    "        tick.label.set_color( 'black' )\n",
    "    for tick in ax.xaxis.get_major_ticks():\n",
    "        tick.label.set_fontsize( 14 )\n",
    "        tick.label.set_color( 'black' )\n",
    "        # tick.label.set_backgroundcolor(\"black\")\n",
    "    \n",
    "    plt.xticks( rotation=45, ha='right' )\n",
    "    \n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# largest countries. \n",
    "showTopTen( 'Geography: Area - total', df )\n",
    "# Some thoughts:\n",
    "#   The invasion of Ukraine should not be considered an act of \n",
    "#       ordinary claustrophobia\n",
    "#   Antarctica: what is it good for?\n",
    "#   Looking at sovereign territories as real-estate for future resources [..]\n",
    "#   ...\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # remnant logic change has broken scale matching\n",
    "\n",
    "# dfWater = pd.concat( [ df[ 'Country' ],\n",
    "#     pd.Series( df[ 'Geography: Area - water' ] ),\n",
    "#     pd.Series( df[ 'Geography: Area - total' ]) ], \n",
    "#     axis=1 ).sort_values( by=[ 'Geography: Area - water' ],\n",
    "#     ascending=False )\n",
    "# \n",
    "\n",
    "# \n",
    "# print(dfWater[ dfWater.Country == 'Chad' ])\n",
    "# print(dffBook[ dffBook.Country == 'Chad' ]['Geography: Area - water'])\n",
    "# print(dffBook[ dffBook.Country == 'Chad' ]['Geography: Area - total'])\n",
    "# \n",
    "# "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# highest percent water area\n",
    "df[ 'Water-area ratio' ] = (\n",
    "    df[ 'Geography: Area - water' ] /\n",
    "    df[ 'Geography: Area - total' ])\n",
    "showTopTen( 'Water-area ratio', df )\n",
    "# The British Indian Ocean territory data here is an outlier arising from an\n",
    "#   apparent inconsistency or ambiguity in geographic description - \n",
    "#   the territory is designated across a very sparse grouping of islands which \n",
    "#   are themselves thin segments of atolls or whole/partial atolls with large \n",
    "#   inner bodies of water. Some interesting reading both for observers of \n",
    "#   colonialism and for ongoing events in the projection of sovereign power \n",
    "#   across large sea vectors:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### British Indian Ocean Territory\n",
    "![British_Indian_Ocean_Territory](https://upload.wikimedia.org/wikipedia/commons/thumb/9/96/British_Indian_Ocean_Territory_in_United_Kingdom.svg/1466px-British_Indian_Ocean_Territory_in_United_Kingdom.svg.png)\n",
    "\n",
    "WIKI: \n",
    ">The only inhabitants are British and U.S. military personnel and associated \n",
    "contractors, who collectively number around 3,000 (2018 figures). The \n",
    "forced removal of Chagossians from the Chagos Archipelago occurred between \n",
    "1968 and 1973. [...] Today, the exiled Chagossians are still trying \n",
    "to return, saying that the forced expulsion and dispossession was unlawful, \n",
    "but the UK government has repeatedly denied them the right of return. The \n",
    "islands are off-limits to Chagossians, casual tourists, and the media. \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# In the course of this study, small island groups with colonial-territorial \n",
    "# names I'm not familiar with keep showing up. Would like to dive into more \n",
    "# detail on each of these; adding \"Ashmore and Cartier Islands\" to the list.\n",
    "\n",
    "ctIslands = [ 'British Indian Ocean Territory' ]\n",
    "\n",
    "# Excluding BIOT as an outlier should reveal a more intuitive distribution.\n",
    "# Better yet, to avoid catching so many islands, let's filter down to countries \n",
    "# whose coastline is no longer than their land boundaries with other countries.\n",
    "\n",
    "showTopTen( 'Water-area ratio',\n",
    "    df[ df[ 'Geography: Land boundaries - total' ] >=\n",
    "        df[ 'Geography: Coastline' ] ],\n",
    "    subtitle=\"Coastline is Equal or Smaller than Land Boundaries\" )\n",
    "\n",
    "# Just out of curiosity (good name for a blog?), the stats for completely\n",
    "# landlocked countries:\n",
    "\n",
    "showTopTen( 'Water-area ratio',\n",
    "    df[ df[ 'Geography: Coastline' ] == 0 ],\n",
    "    subtitle=\"Landlocked countries\" )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# It should be safe to posit that Canada is likely at least somewhat well-known \n",
    "# as a destination for those people with metal detectors you always see a few \n",
    "# hundred meters away at the beach.\n",
    "showTopTen( 'Geography: Coastline', df )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# countries with the largest difference between their lowest and highest point\n",
    "# 'stans represent!\n",
    "# while the China-Nepal border dissects Siggamartha's highest point, China \n",
    "# itself has a lower minimum elevation than Nepal.\n",
    "df[ 'Maximum elevation difference' ] = (\n",
    "    df[ 'Geography: Elevation - highest point' ] -\n",
    "    df[ 'Geography: Elevation - lowest point' ])\n",
    "showTopTen( 'Maximum elevation difference', df )\n",
    "\n",
    "# Flattest places in the world: no point on natural ground is at an ascent of \n",
    "#   more of than five meters from any other point.\n",
    "#   Cayman Islands is easiest on the hips with an M.E.D of one meter\n",
    "showTopTen( 'Maximum elevation difference', df, asc=True )\n",
    "\n",
    "# another for the ctIslands list:\n",
    "ctIslands.append( 'Ashmore and Cartier Islands' )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# highest percent of population in the 65+ bracket \n",
    "# Monaco and then Japan both stand conspicuously out from the distribution\n",
    "# My speculation is that it would tend to be an older people who can afford \n",
    "#   Monaco's prestigious cost of living while, on the other hand, Japan has a \n",
    "#   culturally restrained birth rate - young adults tend to prioritize career \n",
    "#   ascension over family-making (cite).\n",
    "showTopTen( 'People and Society: Age structure - 65 years and over', df )\n",
    "# Japan takes the lead with % younger adults who might be able to \n",
    "#   take on a supporting role to the elderly, while Monaco, having more to\n",
    "#   do the looking-after, is not in the bottom-ten for support ratio.\n",
    "showTopTen( 'People and Society: Dependency ratios - potential support ratio',\n",
    "    df, asc=True )\n",
    "\n",
    "# another for the ctIslands list, a \"remaining vestige of the once vast \n",
    "# territory of New France\"; also one of the fastest-decreasing pop-rates (#4)\n",
    "ctIslands.append( 'Saint Pierre and Miquelon' )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Ratio of irrigated land to total land\n",
    "df[ 'Irrigated-area ratio' ] = (\n",
    "    df[ 'Geography: Irrigated land' ] /\n",
    "    df[ 'Geography: Area - total' ])\n",
    "showTopTen( 'Irrigated-area ratio', df )\n",
    "\n",
    "\n",
    "# Not surprised about most of the t10, who largely have a pastoral image,\n",
    "#   but the Gaza Strip strikes one as being either desert or concrete. \n",
    "#   Still can be mostly true - Gaza as leader is still under 0.6%; an easy\n",
    "#   threshold to reach given its small proportions.\n",
    "\n",
    "\n",
    "def getVal( _df, _ctry, _feat ):\n",
    "    return _df.loc[ _df[ 'Country' ] == _ctry, _feat ].iloc[ 0 ]\n",
    "\n",
    "\n",
    "print( f\"Irrigated area in Gaza Strip is \"\n",
    "       f\"{getVal( df, 'Gaza Strip', 'Irrigated-area ratio' )} km\" )\n",
    "\n",
    "#   Some reading on esyrt in Palestinian agriculture: \n",
    "#       https://socialsciences.mcmaster.ca/kubursi/ebooks/water.htm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Syria's ascendency in population growth must be linked to its even \n",
    "# greater leadership in net migration. What's the story there?\n",
    "# (once the Cocos is excluded as an outlier. Also what's the story? \n",
    "#   In other sources the pop has not seemingly changed by anything like 100%)\n",
    "#  Monaco receiving a steady stream of aspiring casino magnates\n",
    "\n",
    "showTopTen( 'People and Society: Population growth rate', df )\n",
    "showTopTen( 'People and Society: Net migration rate', df )\n",
    "\n",
    "# Most emmigration, and populations in greatest contraction\n",
    "# two very strong categories: either islands (esp. Pacific), or eastern Europe.\n",
    "# (Jordan being the one exception)\n",
    "showTopTen( 'People and Society: Net migration rate', df, asc=True )\n",
    "showTopTen( 'People and Society: Population growth rate', df, asc=True )\n",
    "\n",
    "# more for the ctIslands list\n",
    "ctIslands.append( 'Cocos (Keeling) Islands' )\n",
    "ctIslands.append( 'Anguilla' )\n",
    "ctIslands.append( 'British Virgin Islands' )\n",
    "ctIslands.append( 'Cayman Islands' )  # may as well get into these while we're here\n",
    "ctIslands.append( 'Northern Mariana Islands' )\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Qatar & UAE's men-to-women ratios in the 25-54yo, 55-64yo and 65+ brackets \n",
    "# are startlingly weighted to men, the strongest in the world.\n",
    "showTopTen( 'People and Society: Sex ratio - 25-54 years', df )\n",
    "showTopTen( 'People and Society: Sex ratio - 55-64 years', df )\n",
    "# At the same time, both have (by good measure) the highest value for\n",
    "# the percentage of total population that is 25-54 years old.\n",
    "showTopTen( 'People and Society: Age structure - 25-54 years', df )\n",
    "# Interesting combination - purely speculating, one can imagine a dominating\n",
    "# social discourse might concern the relation of older men to working-age adults.\n",
    "# This consideration is furnished with the dependency ratio, in which\n",
    "# UAE and Qatar are by very, very far the the world chart-toppers:\n",
    "showTopTen( 'People and Society: Dependency ratios - potential support ratio', df )\n",
    "# (What is the DR, and how would these three figures relate?)\n",
    "\n",
    "# meanwhile, in Palau and North Korea, in the 65+ bracket, there are more than \n",
    "# twice as many old codgettes as old codgers.\n",
    "showTopTen( 'People and Society: Sex ratio - 65 years and over', df, asc=True )\n",
    "\n",
    "# for for the Kooky Islands Krew\n",
    "ctIslands.append( 'Saint Barthelemy' )\n",
    "ctIslands.append( 'Faroe Islands' )\n",
    "ctIslands.append( 'Turks and Caicos Islands' )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# People and Society: Current Health Expenditure\n",
    "# Surprised to see US near the top with the impression given by private health \n",
    "# costs.\n",
    "showTopTen( 'People and Society: Current Health Expenditure', df )\n",
    "# Only one country in t10 expenditure is also in t10 physician density (Cuba)\n",
    "showTopTen( 'People and Society: Physicians density', df )\n",
    "# physician density strikes me as vital, as a population's relationship with\n",
    "#   health-seeking, at a preventative stage, [is tied] to its familiarity and \n",
    "#   access to responsive human consultation.\n",
    "# Nice littel one-liner aside: Cuba provides more medical personnel to the \n",
    "#   developing world than all the G8 countries combined.\n",
    "\n",
    "# The only \"first-world\" country in bottom-10 health expenditure, indeed\n",
    "#   leading it, is Monaco, which happens also to:\n",
    "#       - have the second-highest physician density\n",
    "#       - top the \"% pop is 65+\"\n",
    "#   So, with such an old population and such a high density of physicians, \n",
    "#   it may be safe to assume that it is an excellent destination for \n",
    "#   private medical enterprise\n",
    "showTopTen( 'People and Society: Current Health Expenditure', df, asc=True )\n",
    "\n",
    "# for for the Kooky Islands Krew\n",
    "ctIslands.append( 'San Marino' )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Southern Africa nations exclusively form the t10 %pop with HIV-AIDs\n",
    "df[ 'People living with HIV/AIDs as percentage of population' ] = (\n",
    "    df[ 'People and Society: HIV/AIDS - people living with HIV/AIDS' ] /\n",
    "    df[ 'People and Society: Population' ])\n",
    "showTopTen( 'People living with HIV/AIDs as percentage of population', df )\n",
    "\n",
    "# one becomes curious which SA nation has the lowest population with HIV/AIDs\n",
    "sthEquatAfrica = dffBook[\n",
    "    (dffBook[ \"Geography: Map references\" ] == \"Africa\")\n",
    "    & (dffBook[ \"Geography: Geographic coordinates\" ].str.contains( \"S\" ))\n",
    "].Country\n",
    "\n",
    "showTopTen( 'People living with HIV/AIDs as percentage of population',\n",
    "    df[ df[ 'Country' ].isin( sthEquatAfrica ) ], asc=True,\n",
    "    subtitle=\"African Nations South of Equator\" )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the countries that are not islands, Angola - being large, and close to the\n",
    "HIV/AIDs epicentre, appears to have some form of strongly inhibiting factor.\n",
    "A look at recent history identifies a cause for the low prevalence: civil war. \n",
    "\n",
    "> The 27-year civil war in Angola, lasting from 1975 until 2002, kept the spread \n",
    "> of HIV to a minimum due to large parts of the country being inaccessible to \n",
    "> people infected with the virus. During the civil war, individuals from \n",
    "> neighboring countries such as Zambia, Botswana, and Zimbabwe (all countries \n",
    "> with high prevalence rates of HIV) were also not allowed to come into the \n",
    "> country, which played a significant role in controlling the spread of HIV.\n",
    "> [(source: Wikipedia)](https://en.wikipedia.org/wiki/HIV/AIDS_in_Angola#History)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# more for the Kooky Islands Krew\n",
    "ctIslands.append( 'Comoros' )\n",
    "ctIslands.append( 'Sao Tome and Principe' )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Nearly half the people in Nauru and Burma smoke\n",
    "showTopTen( 'People and Society: Tobacco use - total', df )\n",
    "# However, when limited to females, whereas European nations remain in the t10,\n",
    "# the Asia-Pacific nations Burma, Kiribati, Timor Leste, PNG and Indonesia \n",
    "# disappear ( whereas for men they remain).  \n",
    "#   - Gender associations with the act of smoking? \n",
    "#     (eg.: \"smoking is manly (positive) and/or unwomanly (negative)\"\n",
    "\n",
    "# Pattern strikingly reversed for Nauru (#1 t10:total/women, not in t10:men).\n",
    "showTopTen( 'People and Society: Tobacco use - male', df )\n",
    "showTopTen( 'People and Society: Tobacco use - female', df )\n",
    "\n",
    "# No Smoking:\n",
    "showTopTen( 'People and Society: Tobacco use - total', df, asc=True )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# who has the highest combined score for both adult obesity prevalence and \n",
    "# children 4- underweight, where both scores are above feature mean?\n",
    "\n",
    "uFeat = 'People and Society: Children under the age of 5 years underweight'\n",
    "oFeat = 'People and Society: Obesity - adult prevalence rate'\n",
    "\n",
    "df[ 'Generational weight disparity' ] = (df[ uFeat ] + df[ oFeat ])\n",
    "\n",
    "aboveMeans = [ country for country in df[ 'Country' ] if (\n",
    "    df.loc[ df[ 'Country' ] == country, uFeat ].iloc[ 0 ]\n",
    "    >= df[ uFeat ].mean() and\n",
    "    df.loc[ df[ 'Country' ] == country, oFeat ].iloc[ 0 ]\n",
    "    >= df[ oFeat ].mean()) ]\n",
    "\n",
    "showTopTen( 'Generational weight disparity',\n",
    "    df[ df[ 'Country' ].isin( aboveMeans ) ],\n",
    "    subtitle=\"Adult obesity and children underweight both above-mean\" )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# EDUCATION DISPARITIES:\n",
    "expectFeatStr = (\n",
    "    \"People and Society: School life expectancy (primary to tertiary \"\n",
    "    \"education)\")\n",
    "showTopTen( f'{expectFeatStr} - total', df )\n",
    "showTopTen( f'{expectFeatStr} - male', df )\n",
    "showTopTen( f'{expectFeatStr} - female', df )\n",
    "\n",
    "# Pat on the back for Aus: by a modest yet significant margin, has the longest\n",
    "#   total percent competing teriary, AND the position holds true for women as \n",
    "#   much as men."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def getRank( _df, ctry, feature ):\n",
    "    value = _df[ feature ].loc[ _df[ 'Country' ] == ctry ].values[ 0 ]\n",
    "    if str(value) == 'nan': return print( f\"{ctry} is null for\\n{feature}\" )\n",
    "    rank = len( [ v for v in pd.Series( _df[ feature ] ) if v < value ] )\n",
    "    ties = len( [ v for v in pd.Series( _df[ feature ] ) if v == value ] ) - 1\n",
    "    print( f\"With value of [ {value} ], {ctry} is {rank}th-highest for:\\n\"\n",
    "           f\"'{feature}'\\n(out of total {len( cleanCountries )} ranked)\" )\n",
    "    if ties > 0: print( f\"TIED WITH {ties} COUNTRIES\" )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# A pleasant pit-stop in the forests of Suriname:\n",
    "showTopTen( 'Environment: Land use - forest', df )\n",
    "\n",
    "# interestingly, Suriname does very little to leverage this as a resource \n",
    "#   advantage - Suriname's rank in %rev Forst rsrc is 174th.\n",
    "\n",
    "getRank( df, 'Suriname',\n",
    "    'Environment: Revenue from forest resources - forest revenues' )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#   Fairly even, City-States understandably dominating the top 10. \n",
    "showTopTen( 'Environment: Urbanization - urban population', df )\n",
    "showTopTen( 'Environment: Urbanization - urban population', df, asc=True )\n",
    "\n",
    "# Of the least-urbanised, several are pacific territories with relatively \n",
    "#   unfamiliar names: Wallis and Futuna (FR), Montserrat (UK) and Tokelau (NZ). \n",
    "#   To help with attribution, if not decolonization, I submit that the UK and \n",
    "#   French territories swap names.\n",
    "\n",
    "# Liechtenstein... is also there.\n",
    "# \"It is a testimony to the mere political expediency of the purchase that the Princes of Liechtenstein did not visit \n",
    "#   their new principality for almost 100 years.\" [citation needed]\n",
    "\n",
    "# for the Kooky Islands Krew\n",
    "ctIslands.append( 'Wallis and Futuna' )\n",
    "ctIslands.append( 'Montserrat' )\n",
    "ctIslands.append( 'Tokelau' )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### COAL\n",
    "\n",
    "#### Not a glitch: China's appetite"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "showTopTen( 'Energy: Coal - Production', df )\n",
    "showTopTen( 'Energy: Coal - Consumption', df )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Just for scale, this is what the production of the top-ten coal producers \n",
    "looks like. More astonishingly, China remains a net importer - they consume \n",
    "this and more. The equivalent plot for consumption looks the same, except eg.\n",
    "Australia disappears down to 200th in the world; quite a feat for the fourth-\n",
    "largest producer, whereas the rest of the top ten producers are in the top ten \n",
    "consumers (excepting Kazakhstan, who drops out similarly as consumer to 198th)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# update this to return a percap or perGDP ranking.\n",
    "getRank( df, 'Australia', 'Energy: Coal - Consumption' )\n",
    "getRank( df, 'Kazakhstan', 'Energy: Coal - Consumption' )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some figures in greater detail:\n",
    "\n",
    "PRODUCTION: China's production is [ 1.09 ] times that of the rest of the \n",
    "world <br>\n",
    ">   [ 4,314,681,000.00 ]: China's coal production<br>\n",
    ">   [ 3,974,250,000.00 ]: rest of world combined<br>\n",
    " \n",
    "CONSUMPTION: China's consumption is [ 1.27 ] times that of the rest of the \n",
    "world<br>\n",
    ">   [ 4,506,387,000.00 ]: China's coal consumption<br>\n",
    ">   [ 3,534,985,000.00 ]: rest of world combined<br>\n",
    "   "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prodFeat = 'Energy: Coal - Production'\n",
    "consFeat = 'Energy: Coal - Consumption'\n",
    "\n",
    "chinaProd = df[ df.Country == 'China' ][ prodFeat ].sum()\n",
    "chinaCsmp = df[ df.Country == 'China' ][ consFeat ].sum()\n",
    "\n",
    "notChinaProd = df[ df.Country != 'China' ][ prodFeat ].sum()\n",
    "notChinaCsmp = df[ df.Country != 'China' ][ consFeat ].sum()\n",
    "\n",
    "# get longest string length to pad report field\n",
    "pad = (max( [ len( str( i ) )\n",
    "    for i in [ chinaProd, notChinaProd, chinaCsmp, notChinaCsmp ] ] ))\n",
    "\n",
    "productReport = (f\"PRODUCTION: China's production is \"\n",
    "                 f\"[ {(chinaProd / notChinaProd):,.2f} ] times that of the rest of world\\n\"\n",
    "                 f\"   [ {chinaProd:>{pad},.2f} ]: China's coal production\\n\"\n",
    "                 f\"   [ {notChinaProd:>{pad},.2f} ]: rest of world combined\\n\")\n",
    "consmptReport = (f\"\\nCONSUMPTION: China's consumption is \"\n",
    "                 f\"[ {(chinaCsmp / notChinaCsmp):,.2f} ] times the size\\n\"\n",
    "                 f\"of the rest of world combined.\\n\"\n",
    "                 f\"   [ {chinaCsmp:>{pad},.2f} ]: China's coal consumption\\n\"\n",
    "                 f\"   [ {notChinaCsmp:>{pad},.2f} ]: rest of world combined\\n\")\n",
    "\n",
    "print( productReport, consmptReport )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Corobborating the disparity between production and consumption, the export\n",
    "#   figures appear as follows.\n",
    "showTopTen( 'Energy: Coal - Exports', df )\n",
    "\n",
    "# We can get an image of a country's relationship with coal if we look at the \n",
    "#   combined production and imports in ratio to exports. Where this ratio is \n",
    "#   above one, a country has exported abve the total it produced and imported,\n",
    "#   meaning it has sold reserves.\n",
    "#   Refining this further to only the countries whose exports are above the\n",
    "#   world-mean, we can see who has a strong reliance on coal exports.\n",
    "\n",
    "df[ 'Coal: Holdings-to-Export ratio' ] = (\n",
    "    df[ 'Energy: Coal - Exports' ] /\n",
    "    (df[ 'Energy: Coal - Production' ] +\n",
    "     df[ 'Energy: Coal - Imports' ]))\n",
    "\n",
    "aboveMeans = [ country for country in df[ 'Country' ] if (\n",
    "    df.loc[ df[ 'Country' ] == country, 'Energy: Coal - Exports' ].iloc[ 0 ]\n",
    "    >= df[ 'Energy: Coal - Exports' ].mean()) ]\n",
    "\n",
    "showTopTen( 'Coal: Holdings-to-Export ratio',\n",
    "    df[ df[ 'Country' ].isin( aboveMeans ) ] )\n",
    "\n",
    "# In order, the refinement exluded Venezuela, Belarus and Eswatini\n",
    "# such that Russia, South Africa and the Phillipines entered the t10 \"sellers\"\n",
    "\n",
    "\n",
    "# Environment: Revenue from coal - coal revenues\n",
    "#   \"% revenue derived from taxation on coal production\"?\n",
    "#   Compare with \"Exports\" [...]\n",
    "showTopTen( 'Environment: Revenue from coal - coal revenues', df )\n",
    "\n",
    "\n",
    "# Naturally, on the topic of coal, a look at the top CO2 emitters:\n",
    "\n",
    "showTopTen( 'Environment: Air pollutants - carbon dioxide emissions', df )\n",
    "#   China leads by twice its nearest competitor, the US. See coal-relation (hah)\n",
    "# Similar stats for Environment: Air pollutants - methane emission.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Who are the most and least trade-reliant for water? (Hi there, Middle East)\n",
    "# Withdrawrals (municipal, industrial and agricultural) minus renewable sources\n",
    "df[ 'Water withdrawal exposure to trade' ] = (\n",
    "    (df[ 'Environment: Total water withdrawal - municipal' ] +\n",
    "     df[ 'Environment: Total water withdrawal - industrial' ] +\n",
    "     df[ 'Environment: Total water withdrawal - agricultural' ]) -\n",
    "    df[ 'Environment: Total renewable water resources' ])\n",
    "\n",
    "showTopTen( 'Water withdrawal exposure to trade', df, \n",
    "    subtitle=\"Withdrawrals minus resources\" )\n",
    "\n",
    "# Brazil is sitting happy there around the Amazon. Russia and Canada just \n",
    "# melt vast amounts of snow.\n",
    "showTopTen( 'Water withdrawal exposure to trade', df, asc=True, \n",
    "    subtitle=\"Withdrawrals minus resources\" )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Somehow, Serbia's 'Environment: Total water withdrawal - agricultural'\n",
    "#    ORIG:   660.8 million cubic meters (2017 est.)\n",
    "# BECOMES:   900,000,000,000.00\n",
    "\n",
    "dfWater = pd.concat( [ \n",
    "    df[ 'Country' ],\n",
    "    df[ 'Environment: Total water withdrawal - municipal' ],\n",
    "    df[ 'Environment: Total water withdrawal - industrial' ],\n",
    "    df[ 'Environment: Total water withdrawal - agricultural' ],\n",
    "    df[ 'Environment: Total renewable water resources' ] ], \n",
    "    axis=1 ).sort_values( \n",
    "        by=[ 'Environment: Total water withdrawal - agricultural' ], \n",
    "        ascending=False )[ :10 ]\n",
    "\n",
    "# dfWater[ dfWater[ 'Country' ] == \"Serbia\" ]\n",
    "# dfWaterFB[ dfWaterFB[ 'Country' ] == \"Serbia\" ]\n",
    "print( \"This should be 660.8 million: \", \n",
    "    dfWater.loc[ dfWater[ 'Country' ] == \"Serbia\", \n",
    "    \"Environment: Total water withdrawal - agricultural\" ].iloc[ 0 ] )\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfWaterFB = pd.concat( [ \n",
    "    dffBook[ 'Country' ],\n",
    "    dffBook[ 'Environment: Total water withdrawal - municipal' ],\n",
    "    dffBook[ 'Environment: Total water withdrawal - industrial' ],\n",
    "    dffBook[ 'Environment: Total water withdrawal - agricultural' ],\n",
    "    dffBook[ 'Environment: Total renewable water resources' ] ], \n",
    "    axis=1 )\n",
    "\n",
    "# dfWaterFB[ dfWaterFB[ 'Country' ] == \"Serbia\" ]\n",
    "print( \"This should be 660.8 million: \", \n",
    "    dfWaterFB.loc[ dfWaterFB[ 'Country' ] == \"Serbia\", \n",
    "    \"Environment: Total water withdrawal - agricultural\" ].iloc[ 0 ] )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ctIslands.append('Cape Verde')\n",
    "ctIslands.append('Saint Vincent and the Grenadines')\n",
    "ctIslands.append('Saint Kitts and Nevis')\n",
    "ctIslands.append('Saint Lucia')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'Economy: Real GDP (purchasing power parity)'\n",
    "# Something funky going on with Iran \n",
    "\n",
    "# It's taken a \"trillion\" relevant to a remnant-value (2018) and applied it\n",
    "#   to the firstmatch-value (2020). \n",
    "\n",
    "# if second match, truncate remainder at \n",
    "\n",
    "# Need to truncate all remainder at position of second match.\n",
    "#     \n",
    "\n",
    "# IRAN REAL GDP\n",
    "#    FB:$1,044,310,000,000 (2020 est.)$1,027,240,000,000 (2019 est.)$1.102 trillion (2018 est.)\n",
    "#    DF:1044310000000000006815744.00\n",
    "\n",
    "chiRGDP_fBook = getVal( dffBook, 'China',\n",
    "    'Economy: Real GDP (purchasing power parity)' )\n",
    "chiRGDP_df = getVal( df, 'China',\n",
    "    'Economy: Real GDP (purchasing power parity)' )\n",
    "iraRGDP_fBook = getVal( dffBook, 'Iran',\n",
    "    'Economy: Real GDP (purchasing power parity)' )\n",
    "iraRGDP_df = getVal( df, 'Iran',\n",
    "    'Economy: Real GDP (purchasing power parity)' )\n",
    "\n",
    "print( f\"CHINA REAL GDP\\n   FB:{chiRGDP_fBook}\\n   DF:{chiRGDP_df}\" )\n",
    "print( f\"IRAN REAL GDP\\n   FB:{iraRGDP_fBook}\\n   DF:{iraRGDP_df:.2f}\" )\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "listStart = 83\n",
    "showNumber = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print( f\"{listStart}:{listStart + showNumber}\" )\n",
    "for i in list( df.columns )[ listStart:listStart + showNumber ]:\n",
    "    showTopTen( i, df )\n",
    "    listStart += showNumber\n",
    "\n",
    "newDrops = [\n",
    "    'Government: Country name - etymology',\n",
    "    'Economy: Real GDP per capita - note',\n",
    "    'Government: Suffrage'\n",
    "    ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# the Kooky Islands Krew (ctIslands)\n",
    "#   appears frequently on the bottom/top ten because it is takes less\n",
    "#   of an event in global terms to have a proportionately large effect\n",
    "#   on the small sample, be it a population, an area total and so on. \n",
    "\n",
    "# Things that China is in the top-ten/5/3/1 of\n",
    "# (Who else are the \"most top 10/5/3/1\" countries?)\n",
    "# combine bottom-tens somehow?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generate CORRELATION DICTIONARY where keys are correlations,\n",
    "#   values are key-value pairs of baseCol : compareDict\n",
    "#   CompareDict key-value is col num : correlation coefficient\n",
    "\n",
    "# correlDict = { }\n",
    "# baseCol = 1\n",
    "# while True:\n",
    "#     colCorrs = { }\n",
    "#     for colPos in range( baseCol + 1, df.shape[ 1 ] ):\n",
    "#         colCorrs[ colPos ] = df.iloc[ :, baseCol ].corr( df.iloc[ :, colPos ] )\n",
    "#     correlDict[ baseCol ] = colCorrs\n",
    "#     baseCol += 1\n",
    "#     if baseCol == df.shape[ 1 ]: print( f\"Completed correlations\" ); break\n",
    "# \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# move all most defs to import module, except where useful for process \n",
    "# communication\n",
    "# Heh. mosdef.\n",
    "\n",
    "# END"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}